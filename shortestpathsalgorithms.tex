%========== Shortest Paths Algorithms ==========%

\chapter{Shortest Paths Algorithms}
\label{ch:shortestpathsalgorithms}

\textbf{Pensum} 24 \cite{clrs} \\\\
\textbf{Assignments} 13-3 \\\\
\textbf{Algorithms} Single-source, Dijkstra, Bellman-Ford, breadth-first
search \\\\
\textbf{Keywords} Triangle inequality, relaxation, optimal substructure,
represenation invariant
\vspace{1in}

\noindent We are given a weighted, directed graph $G = (V, E)$, with weight
function $w : E \rightarrow \mathbb{R}$, mapping the edges of the graph to
real-valued weights. The \textit{weight} $w(p)$ of a \textit{path} $p =
\langle v_0, v_1, \dots, v_k \rangle$ is the sum of the weights of its
constituent edges.
\begin{align}
	w(p) = \sum_{k}^{i=1} w(v_{i-1}, v_i)
\end{align}
We define the shortest path weight $\delta(u, v)$ from $u$ to $v$ by
\begin{align}
	\delta(u, v) =
	\begin{cases}
		min\{w(p): u \rightarrow v\}
		& \textnormal{if there is a path from $u$ to $v$,} \\
		\infty & \textnormal{otherwise.}
	\end{cases}
\end{align}
A \textit{shortest path} $p$ from $v$ to $u$ is defined as $w(p) =
\delta(u, v)$.

\section{Properties}
We give the properties of shortest paths.

\begin{description}
	\item \textbf{The Triangle Inequality} \cite[p.~671, thm. 24.10]{clrs} \\
For any edge $(u, v) \in E$, we have $\delta(s, v) \leq \delta(s, u) +
w(u, v)$ - meaning that a shortest path fulfills the triangle inequality (see
appendix \ref{appendix:equations|eqn:triangle-inequality}).

	\item \textbf{Upper-bound} \cite[p.~671-672, thm. 24.11]{clrs} \\
We always have $v.d \geq \delta(s, v)$ for all vertices $v \in V$, and once
$v.d = \delta(s, v)$, it never changes.

	\item \textbf{No-path} \cite[p.~672, thm. 24.12]{clrs} \\
If there is no path from $s$ to $v$, then we always have $v.d = \delta(s, v) =
\infty$.

	\item \textbf{Convergence} \cite[p.~672-673, thm. 24.14]{clrs} \\
If $s \leadsto u \rightarrow v$ is a shortest path in $G$ for some
$u, v \in V$, and if $u.d = \delta(s, u)$ at any time prior to relaxing edge
$(u, v)$, then $v.d = \delta(s,v)$ at all times afterward.
	\item \textbf{Path-relaxation} \cite[p.~673, thm. 24.15]{clrs} \\
If $p = \langle v_0, v_1, \dots, v_k \rangle$ is a shortest path from
$s = v_0$ to $v_k$, and we relax the edge of $p$ in order $(v_0, v_1),
(v_1, v_2), \dots, (v_{k-1}, v_k)$, then $v_k.d = \delta(s, v_k)$. This
property holds regardless of any other relaxation steps that occur, even if
they are intermixed with relaxations of the edges of $p$.
	\item \textbf{Predecessor-subgraph} \cite[p.~676, thm. 24.17]{clrs} \\
Once $v.d = \delta(s, v)$ for all $v \in V$, the predecessor subgraph is a
shortest-paths tree rooted at $s$.
\end{description}

\newpage
\section{Optimal Substructure}
Shortest paths algorithms typically rely on the property that a shortest path
between two vertices contains other shortest paths within it. This is one of
the key indicators of \textit{dynamic programming} (see chapter
\ref{ch:dynamicprogramming}) and \textit{greedy} (see chapter
\ref{ch:greedyalgorithms}) problems.

\begin{lemma}
\label{lemma:24.1}
	\textbf{Subpaths of shortest paths are shortest paths} \\
	Given a weighted digraph $G = (V, E)$ with weight function $w \rightarrow
	\mathbb{R}$, let $p = \langle v_0, v_1, \dots, v_k \rangle$ be a shortest
	path from $v_0$ to $v_k$ and, for any $i$ and $j$ such that $0 \leq i \leq
	j \leq k$, let $p_{ij} = \langle v_i, v_{i+1}, \dots, v_{j-1}, v_j
	\rangle$ be a subpath of $p$ from vertex $v_i$ to $v_j$. Then $p_{ij}$ is
	a shortest path from $v_i$ to $v_j$.
\end{lemma} 

\begin{proof} \textnormal{\cite[p.~645, thm.~24.1]{clrs}} \\
	If we decompose path $p$ into $v_0 \buildrel{p_{0i}}\over\leadsto\; v_i
	\buildrel{p_{ij}}\over\leadsto\; v_j \buildrel{p_{jk}}\over\leadsto\; v_k$,
	then we have that $w(p) = w(p_{0i}) + w(p_{ik}) + w(p_{jk})$. Now assume
	that there is a path $p'_{ij}$ from $v_i$ to $v_j$ with $w(p'_{ij}) <
	w(p_{ij})$. Then $v_0 \buildrel{p_{0i}}\over\leadsto\; v_i
	\buildrel{p'_{ij}}\over\leadsto\; v_j
	\buildrel{p_{jk}}\over\leadsto\; v_k$ is a path from $v_0$ to $v_k$ whose
	weight is less than $w(p)$, which contradicts the assumption that $p$ is
	a shortest path from $v_0$ to $v_k$.
\end{proof}

\section{Single-source Shortest Path}
% ch. 24, CLRS
Given a graph $G = (V, E)$, we want to find a shortest path from a given
\textit{source} vertex $s \in V$ to each vertex $v \in V$.
\\\\
\noindent We can reduce many other problems to the problem defined above.
\begin{description}
	\item \textbf{Single-destination} Find a shortest path to a given
\textit{destination} vertex $t$ from a vertex $v$ - this is the opposite
problem. By reversing the edge directions we effectively reduced it to a
source-source problem.
	\item \textbf{Single-pair} Find a shortest path from $u$ to $v$. If we let
$u$ be the source vertex, then this is the exact same problem. All known
algorithms for this problem have the same worst-case asymptotic running-time
as the best single-source algorithms. % TODO: Elaborate on why, prove it maybe!
	\item \textbf{All-pair} Find a shortest path from $u$ to $v$ for every
pair of vertices $u$ and $v$. This is essentially the single-source problem,
but for all vertices in the set as the source.
\end{description}

\subsection{Subprocedures}
We will make use of a number of subprocedures in the following algorithms.
\begin{minipage}[t]{0.45\linewidth}
	\begin{algorithm}[H]
		\caption{Init Single-source}
		\label{alg:init-single-source}
		
		\SetKwInOut{In}{Input}
		\SetKwInOut{Out}{Output}
		\SetKwInOut{Time}{Complexity}
		\SetKw{Nil}{NIL}
		
		\SetKwFunction{InitSingleSource}{InitSingleSource}
		
%		\In{A graph $G$ and a source vertex $s$.}
%		\Out{Initializes the nodes attributes of the graph $G$.}
		\Time{$\Theta(V)$-time.}
		
		\BlankLine
		\InitSingleSource($G$, $s$) \\
		\Begin
		{
			\For{\textnormal{each vertex } $v \in G.V$}
			{
				$v.d = \infty$ \\
				$v.\pi = $ \Nil
			}
			$s.d = 0$
		}
	\end{algorithm}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[t]{0.45\linewidth}
	\begin{algorithm}[H]
		\caption{Relax edge}
		\label{alg:relax}
		
		\SetKwInOut{In}{Input}
		\SetKwInOut{Out}{Output}
		\SetKwInOut{Time}{Complexity}
		
		\SetKw{Nil}{NIL}
		
		\SetKwFunction{Relax}{Relax}
		
%		\In{Vertices $u$ and $v$, and weight function $w$.}
%		\Out{Relaxes the path to $v$, if going through $u$ is shorter.}
		\Time{$\Theta(1)$-time.}
		
		\BlankLine
		\Relax($u$, $v$, $w$) \\
		\Begin
		{
			\If{$u.d + w(u, v) < v.d$}
			{
				$v.d = u.d + w(u, v)$ \\
				$v.\pi = u$
			}
		}
	\end{algorithm}
\end{minipage}

\newpage
\section{Bellman-Ford Algorithm}
% p. 651, CLRS
The algorithm produces a shortest path if no negative cycles are reachable
from the source, indicating success by returning the boolean value
\texttt{true}, otherwise it returns \texttt{false}. It works by continually
relaxing edges, progressively decreasing the distance estimate on the weight
of a shortest path from the source $s$ to each vertex $v \in V$.
\\\\
\begin{algorithm}[H]
	\caption{Bellman-Ford algorithm}
	\label{alg:bellman-ford}
	
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	
	\SetKw{True}{true}
	\SetKw{False}{false}
	
	\SetKwFunction{BellmanFord}{BellmanFord}
	\SetKwFunction{InitSingleSource}{InitializeSingleSource}
	\SetKwFunction{Relax}{Relax}
	
	\Input{A graph $G$, a weight function $w$ and a source vertex $s$.}
	\Output{In-place shortest path of the graph $G$.}
	
	\BlankLine
	\BellmanFord($G$, $w$, $s$) \\
	\Begin
	{
		\InitSingleSource($G$, $s$) \\
		\For{$i = 1$ \KwTo $|G.V| - 1$}
		{
			\For{\textnormal{each edge } $(u, v) \in G.E$}
			{
				\Relax($u$, $v$, $w$)
			}
		}
		\For{\textnormal{each edge } $(u, v) \in G.E$}
		{
			\If{$v.d > u.d + w(u, v)$}{ \Return \False }
		}
		\Return \True
	}
\end{algorithm}

\subsection{Analysis}
The initialization on line 3 takes $O(V)$-time. The loop on lines 4--8 is run
exactly $|V|-1$ times, each pass relaxes every edge once $\Theta(E)$, giving
us the most prominent contribution to the running-time $O(VE)$. The last loop
checks for negative cycles reachable from the source, contributing just $O(E)$.

\newpage
\section{Dijkstra's Algorithm}
% p. 658, CLRS
The algorithm works only on directed graphs with nonnegative edge-weights,
that is we assume that $w(u, v) \geq 0$ for each edge $(u, v) \in E$.
\\\\
\begin{algorithm}[H]
	\caption{Dijkstra's algorithm}
	\label{alg:dijkstra}
	
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	
	\SetKwFunction{Dijkstra}{Dijkstra}
	\SetKwFunction{InitSingleSource}{InitializeSingleSource}
	\SetKwFunction{ExtractMin}{ExtractMin}
	\SetKwFunction{Relax}{Relax}
	
	\Input{A graph $G$, a weight function $w$ and a source vertex $s$.}
	\Output{In-place shortest path of the graph $G$.}
	
	\BlankLine
	\Dijkstra($G$, $w$, $s$) \\
	\Begin
	{
		\InitSingleSource($G$, $s$) \\
		$S = \emptyset$ \\
		$Q = G.V$ \\
		\While{$Q \neq \emptyset$}
		{
			$u = $ \ExtractMin($Q$) \\
			$S = S \cup \{u\}$ \\
			\For{\textnormal{each vertex } $v \in G.Adj[u]$}
			{
				\Relax($u$, $v$, $w$)
			}
		}
	}
\end{algorithm}

\subsection{Analysis}
In the case of Dijkstra's algorithm we reason that the use of an array for the
priority queue is better suited for the problem. Thereby operations cost
\begin{description}
	\item \texttt{ExtractMin} takes $\Theta(n)$.
	\item \texttt{Insert} and \texttt{DecreaseKey} takes $\Theta(1)$.
\end{description}
In the outer loop, we perform $|V|$ extractions, each of which costs $O(V)$,
giving us $O(V^2)$. In the inner loop we consider each vertex in the adjacency
list exactly once, which by aggregate analysis gives us exactly $|E|$ implicit
calls to \texttt{DecreaseKey}, each taking $O(1)$. This amounts to a total of
$O(V^2 + E) = O(V^2)$.

If the graph if sufficiently sparse, particularly when
$E = o(\frac{V^2}{\lg V})$, we may use a min-heap priority queue instead. We
then have $|V|$ extractions of $O(\lg V)$, and $|E|$ decrease key operations,
which yields a running-time of $O((V+E)\lg V)$, which is $O(E \lg V)$ if all
vertices are reachable from the source.

\newpage
\subsection{Proof}
We state and prove the loop invariant. It suffices to show that this holds for
each vertex at the time it gets added to $S$, we will rely on the upper-bound
property to show that it holds at all times thereafter.
\\\\
\noindent \textbf{Invariant} \\
that the maintains; At the start of each iteration of the while loop
$v.d = \delta(s, v)$ for each vertex $v \in V$.
\\\\
\noindent \textbf{Initialization} \\
Initially, $S = \emptyset$, and so the invariant is trivially true.
\\\\
\noindent \textbf{Maintenance} \\
Suppose that we add a vertex $u$ to the set $S$, where $u.d \neq \delta(s, u)$
for purposes of contraction. First, we must have that $u \neq s$, since $s$ is
the first to be pulled out of the queue because $s.d = 0$. As a consequence of
this $S \neq \empty$ at the time where $u$ is added, since $s$ has already
been added. There must be a path from $s$ to $u$, otherwise $\delta(s, u) =
\infty$ by the no-path property, which would violate the assumption. This
means that there must be a shortest path from $s$ to $u$. Prior to adding $u$
to $S$, path $p$ connects a vertex in $S$ (namely $s$) to a vertex in $V - S$
(namely $u$). Consider the connecting vertices on such a path, $y \in S$ and
the predecessor of $y$, $x \in V - S$. We have that
\begin{align}
	\underbrace{s \buildrel{p_1}\over\leadsto\; y}_{S}
	\rightarrow
	\underbrace{x \buildrel{p_2}\over\leadsto\; u}_{V - S} \nonumber
\end{align}
We claim that $y.d = \delta(s, y)$ when $u$ is added to $S$. To prove this, we
observe that $x \in S$, hence $x.d = \delta(s, x)$ when $x$ was added. The
edge $(x, y)$ was then relaxed and the claim then follows from the convergence
property.

Because $y$ appears before $u$, we have that $\delta(s, y) \leq \delta(s, u)$,
and by the upper-bound property we have that $y.d = \delta(s, y) \leq
\delta(s, u) \leq u.d$. However, since $y, u \in V - S$ at the time where $u$
was chosen, we must have that $y.d = \delta(s, y) = \delta(s, u) = u.d$. The
consequence of this is that $u$ is in fact $y$, by which it follows that
$u.d = \delta(s, u)$, which is a contradiction to our initial statement.
\\\\
\noindent \textbf{Termination} \\
As a direct consequence of the exit-condition, $Q = \emptyset$, which by the
loop invariant that $Q = V - S$ implies that $S = V$. Thus, $u.d =
\delta(s, u)$ for all vertices $u \in V$.

